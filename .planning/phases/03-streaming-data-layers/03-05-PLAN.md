---
phase: 03-streaming-data-layers
plan: 05
type: execute
wave: 3
depends_on:
  - "03-01"
  - "03-03"
  - "03-04"
files_modified:
  - Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDDataLayerManagerTest.cpp
  - Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingTelemetryTest.cpp
  - Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingSourceVehicleTest.cpp
autonomous: true

must_haves:
  truths:
    - "All unit tests pass in automation runner"
    - "Data Layer manager correctly wraps UDataLayerSubsystem"
    - "Telemetry system logs and calculates averages correctly"
    - "Vehicle streaming configuration applies correct settings"
  artifacts:
    - path: "Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDDataLayerManagerTest.cpp"
      provides: "Data Layer manager unit tests"
      min_lines: 60
    - path: "Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingTelemetryTest.cpp"
      provides: "Telemetry subsystem unit tests"
      min_lines: 80
    - path: "Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingSourceVehicleTest.cpp"
      provides: "Vehicle streaming configuration tests"
      min_lines: 50
  key_links:
    - from: "Unit Tests"
      to: "GSDDataLayerManager, GSDStreamingTelemetry, GSDStreamingSourceComponent"
      via: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
      pattern: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
---

<objective>
Create unit tests for GSDDataLayerManager, GSDStreamingTelemetry, and vehicle streaming configuration.

Purpose: Verify all Phase 3 systems work correctly in isolation. Tests follow existing patterns from Phase 2.

Output: Three test files with comprehensive coverage of Data Layer management, telemetry logging, and vehicle streaming configuration.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-streaming-data-layers/03-RESEARCH.md

# Reference existing test patterns
@Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingSourceTest.cpp
@Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDHLODTest.cpp
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GSDDataLayerManager Unit Tests</name>
  <files>Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDDataLayerManagerTest.cpp</files>
  <action>
Create unit tests for GSDDataLayerManager following existing patterns.

Test file structure:
```cpp
#include "CoreMinimal.h"
#include "Misc/AutomationTest.h"
#include "Subsystems/GSDDataLayerManager.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Subsystem can be created
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDDataLayerManagerCreationTest,
    "GSD.CityStreaming.DataLayerManager.Creation",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDDataLayerManagerCreationTest::RunTest(const FString& Parameters)
{
    // Note: UWorldSubsystem requires a world context
    // For unit tests, we verify the class can be instantiated
    // Full integration tests require PIE or game world

    UGSDDataLayerManager* Manager = NewObject<UGSDDataLayerManager>();
    TestNotNull("Manager should be created", Manager);

    return true;
}

// Test 2: GetRuntimeDataLayerNames returns array (even if empty without world)
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDDataLayerManagerGetNamesTest,
    "GSD.CityStreaming.DataLayerManager.GetRuntimeDataLayerNames",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDDataLayerManagerGetNamesTest::RunTest(const FString& Parameters)
{
    UGSDDataLayerManager* Manager = NewObject<UGSDDataLayerManager>();
    TestNotNull("Manager should be created", Manager);

    if (Manager)
    {
        // Without world context, returns empty array (not crash)
        TArray<FName> Names = Manager->GetRuntimeDataLayerNames();
        TestTrue("GetRuntimeDataLayerNames should return valid array", true);
    }

    return true;
}

// Test 3: IsDataLayerActivated handles invalid names gracefully
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDDataLayerManagerInvalidLayerTest,
    "GSD.CityStreaming.DataLayerManager.InvalidLayerHandling",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDDataLayerManagerInvalidLayerTest::RunTest(const FString& Parameters)
{
    UGSDDataLayerManager* Manager = NewObject<UGSDDataLayerManager>();
    TestNotNull("Manager should be created", Manager);

    if (Manager)
    {
        // Querying non-existent layer should return false (not crash)
        bool bResult = Manager->IsDataLayerActivated(FName("NonExistentLayer"));
        TestFalse("Non-existent layer should report as not activated", bResult);
    }

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

Key test patterns:
- Use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro
- Test flags: ApplicationContextMask | ProductFilter
- Always test for null before using objects
- Test edge cases (invalid names, null world context)
  </action>
  <verify>Test file exists with at least 3 test implementations</verify>
  <done>GSDDataLayerManagerTest.cpp created with creation, GetNames, and invalid layer tests</done>
</task>

<task type="auto">
  <name>Task 2: Create GSDStreamingTelemetry Unit Tests</name>
  <files>Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingTelemetryTest.cpp</files>
  <action>
Create unit tests for GSDStreamingTelemetry following existing patterns.

Test file structure:
```cpp
#include "CoreMinimal.h"
#include "Misc/AutomationTest.h"
#include "Subsystems/GSDStreamingTelemetry.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Subsystem can be created
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingTelemetryCreationTest,
    "GSD.CityStreaming.StreamingTelemetry.Creation",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingTelemetryCreationTest::RunTest(const FString& Parameters)
{
    UGSDStreamingTelemetry* Telemetry = NewObject<UGSDStreamingTelemetry>();
    TestNotNull("Telemetry should be created", Telemetry);

    return true;
}

// Test 2: LogStreamingEventForTest adds events correctly
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingTelemetryLogEventTest,
    "GSD.CityStreaming.StreamingTelemetry.LogEvent",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingTelemetryLogEventTest::RunTest(const FString& Parameters)
{
    UGSDStreamingTelemetry* Telemetry = NewObject<UGSDStreamingTelemetry>();
    TestNotNull("Telemetry should be created", Telemetry);

    if (Telemetry)
    {
        // Log test events
        Telemetry->LogStreamingEventForTest(TEXT("Cell_01"), 15.5f);
        Telemetry->LogStreamingEventForTest(TEXT("Cell_02"), 22.0f);

        const TArray<FGSDStreamingEvent>& Events = Telemetry->GetRecentEvents();
        TestEqual("Should have 2 events", Events.Num(), 2);

        if (Events.Num() >= 2)
        {
            TestEqual("First event CellName", Events[0].CellName, FString("Cell_01"));
            TestEqual("First event LoadTimeMs", Events[0].LoadTimeMs, 15.5f);
            TestEqual("Second event CellName", Events[1].CellName, FString("Cell_02"));
            TestEqual("Second event LoadTimeMs", Events[1].LoadTimeMs, 22.0f);
        }
    }

    return true;
}

// Test 3: GetAverageLoadTimeMs calculates correctly
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingTelemetryAverageTest,
    "GSD.CityStreaming.StreamingTelemetry.AverageLoadTime",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingTelemetryAverageTest::RunTest(const FString& Parameters)
{
    UGSDStreamingTelemetry* Telemetry = NewObject<UGSDStreamingTelemetry>();
    TestNotNull("Telemetry should be created", Telemetry);

    if (Telemetry)
    {
        // Empty telemetry returns 0
        float AvgEmpty = Telemetry->GetAverageLoadTimeMs();
        TestEqual("Empty average should be 0", AvgEmpty, 0.0f);

        // Log events
        Telemetry->LogStreamingEventForTest(TEXT("Cell_01"), 10.0f);
        Telemetry->LogStreamingEventForTest(TEXT("Cell_02"), 20.0f);
        Telemetry->LogStreamingEventForTest(TEXT("Cell_03"), 30.0f);

        // Average should be 20.0
        float AvgLoaded = Telemetry->GetAverageLoadTimeMs();
        TestEqual("Average should be 20.0", AvgLoaded, 20.0f);
    }

    return true;
}

// Test 4: Event buffer respects max size
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingTelemetryBufferTest,
    "GSD.CityStreaming.StreamingTelemetry.BufferLimit",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingTelemetryBufferTest::RunTest(const FString& Parameters)
{
    UGSDStreamingTelemetry* Telemetry = NewObject<UGSDStreamingTelemetry>();
    TestNotNull("Telemetry should be created", Telemetry);

    if (Telemetry)
    {
        // Log more than MaxRecentEvents (100)
        for (int32 i = 0; i < 150; ++i)
        {
            Telemetry->LogStreamingEventForTest(FString::Printf(TEXT("Cell_%d"), i), 10.0f);
        }

        const TArray<FGSDStreamingEvent>& Events = Telemetry->GetRecentEvents();
        TestTrue("Events should be capped at MaxRecentEvents", Events.Num() <= 100);
    }

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```
  </action>
  <verify>Test file exists with at least 4 test implementations covering creation, logging, average, and buffer limit</verify>
  <done>GSDStreamingTelemetryTest.cpp created with comprehensive tests</done>
</task>

<task type="auto">
  <name>Task 3: Create Vehicle Streaming Configuration Tests</name>
  <files>Plugins/GSD_CityStreaming/Source/GSD_CityStreaming/Private/Tests/GSDStreamingSourceVehicleTest.cpp</files>
  <action>
Create unit tests for vehicle-specific streaming configuration.

Test file structure:
```cpp
#include "CoreMinimal.h"
#include "Misc/AutomationTest.h"
#include "Components/GSDStreamingSourceComponent.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: ConfigureForVehicle sets predictive loading
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingSourceVehicleConfigTest,
    "GSD.CityStreaming.StreamingSource.VehicleConfig",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingSourceVehicleConfigTest::RunTest(const FString& Parameters)
{
    UGSDStreamingSourceComponent* Component = NewObject<UGSDStreamingSourceComponent>();
    TestNotNull("Component should be created", Component);

    if (Component)
    {
        // Configure for standard vehicle
        Component->ConfigureForVehicle(false, 1000.0f);

        TestTrue("Predictive loading should be enabled", Component->IsPredictiveLoadingEnabled());
        TestEqual("Loading range multiplier should be 1.0", Component->GetLoadingRangeMultiplier(), 1.0f);
        TestEqual("Velocity threshold should be 1000", Component->GetPredictiveLoadingThreshold(), 1000.0f);
    }

    return true;
}

// Test 2: ConfigureForVehicle with fast vehicle flag
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingSourceFastVehicleTest,
    "GSD.CityStreaming.StreamingSource.FastVehicle",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingSourceFastVehicleTest::RunTest(const FString& Parameters)
{
    UGSDStreamingSourceComponent* Component = NewObject<UGSDStreamingSourceComponent>();
    TestNotNull("Component should be created", Component);

    if (Component)
    {
        // Configure for fast vehicle
        Component->ConfigureForVehicle(true, 1500.0f);

        TestTrue("Predictive loading should be enabled", Component->IsPredictiveLoadingEnabled());
        TestEqual("Loading range multiplier should be 2.0 for fast vehicle", Component->GetLoadingRangeMultiplier(), 2.0f);
        TestEqual("Velocity threshold should be 1500", Component->GetPredictiveLoadingThreshold(), 1500.0f);
    }

    return true;
}

// Test 3: Getters return correct values after manual changes
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDStreamingSourceGetterTest,
    "GSD.CityStreaming.StreamingSource.Getters",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingSourceGetterTest::RunTest(const FString& Parameters)
{
    UGSDStreamingSourceComponent* Component = NewObject<UGSDStreamingSourceComponent>();
    TestNotNull("Component should be created", Component);

    if (Component)
    {
        // Set loading range multiplier manually
        Component->SetLoadingRangeMultiplier(3.0f);
        TestEqual("GetLoadingRangeMultiplier should return 3.0", Component->GetLoadingRangeMultiplier(), 3.0f);

        // ConfigureForVehicle should override
        Component->ConfigureForVehicle(false);
        TestEqual("ConfigureForVehicle should reset multiplier to 1.0", Component->GetLoadingRangeMultiplier(), 1.0f);
    }

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```
  </action>
  <verify>Test file exists with at least 3 test implementations for vehicle configuration</verify>
  <done>GSDStreamingSourceVehicleTest.cpp created with vehicle config, fast vehicle, and getter tests</done>
</task>

<task type="auto">
  <name>Task 4: Run All Tests and Verify Pass</name>
  <files>N/A</files>
  <action>
Verify all Phase 3 unit tests pass.

Since this is an Unreal project, tests run via:
1. Unreal Editor Session Frontend
2. Command line: `RunUAT RunTests -project=...`
3. Visual Studio test explorer (if configured)

For this verification task:
1. Confirm all test files exist
2. Confirm test files compile (check for syntax errors by reading them back)
3. Document expected test count

Expected tests:
- GSDDataLayerManagerTest.cpp: 3 tests
- GSDStreamingTelemetryTest.cpp: 4 tests
- GSDStreamingSourceVehicleTest.cpp: 3 tests
- (Existing) GSDStreamingSourceTest.cpp: 3 tests (from Phase 2)

Total: 13 tests

Note: Actual test execution requires Unreal Editor. This task verifies compilation and structure.
  </action>
  <verify>All test files exist and contain expected number of IMPLEMENT_SIMPLE_AUTOMATION_TEST macros</verify>
  <done>All Phase 3 test files created with 10 new tests (3 + 4 + 3). Ready for execution in Editor.</done>
</task>

</tasks>

<verification>
1. All three test files exist in Private/Tests/
2. Each test file compiles without errors
3. Test names follow GSD.CityStreaming.[Subsystem].[Feature] pattern
4. Tests use correct flags (ApplicationContextMask | ProductFilter)
5. Expected 10 new tests created
</verification>

<success_criteria>
- [x] GSDDataLayerManagerTest.cpp created with 3 tests
- [x] GSDStreamingTelemetryTest.cpp created with 4 tests
- [x] GSDStreamingSourceVehicleTest.cpp created with 3 tests
- [x] All tests follow existing patterns
- [x] Total Phase 3 test count: 10 new tests
</success_criteria>

<output>
After completion, create `.planning/phases/03-streaming-data-layers/03-05-SUMMARY.md`
</output>
