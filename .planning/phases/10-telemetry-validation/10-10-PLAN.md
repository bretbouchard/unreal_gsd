---
phase: 10-telemetry-validation
plan: 10
type: execute
wave: 5
depends_on: [10-01, 10-02, 10-03, 10-04, 10-05, 10-06, 10-07, 10-08, 10-09]
files_modified:
  - Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp
  - Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp
autonomous: true
must_haves:
  truths:
    - "All telemetry subsystems have automation tests"
    - "All validation commandlets have tests"
    - "Editor widget functionality is verified"
    - "Integration tests confirm end-to-end functionality"
  artifacts:
    - path: "Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp"
      provides: "Telemetry subsystem tests"
      contains: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
    - path: "Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp"
      provides: "Validation commandlet and widget tests"
      contains: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
  key_links:
    - from: "GSDTelemetryTests"
      to: "UGSDPerformanceTelemetry"
      via: "Subsystem testing"
      pattern: "GetSubsystem<UGSDPerformanceTelemetry>"
---

<objective>
Create comprehensive verification tests for telemetry and validation systems.

Purpose: Verify all Phase 10 systems work correctly through automation tests.
Output: Automation tests for telemetry subsystems, commandlets, and editor widgets.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-telemetry-validation/10-RESEARCH.md

# Reference existing test patterns
@Plugins/GSD_Crowds/Source/GSD_Crowds/Private/Tests/GSDCrowdTests.cpp
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Telemetry Subsystem Tests</name>
  <files>Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp</files>
  <action>
Create automation tests for telemetry subsystems.

**GSDTelemetryTests.cpp:**
```cpp
#include "CoreMinimal.h"
#include "Misc/AutomationTest.h"
#include "Subsystems/GSDPerformanceTelemetry.h"
#include "Subsystems/GSDStreamingTelemetry.h"
#include "Types/GSDTelemetryTypes.h"
#include "Engine/GameInstance.h"
#include "Engine/World.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test: Performance telemetry subsystem initialization
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDPerformanceTelemetryInitTest,
    "GSD.Telemetry.PerformanceTelemetry.Initialization",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDPerformanceTelemetryInitTest::RunTest(const FString& Parameters)
{
    // Create test world
    UWorld* TestWorld = NewObject<UWorld>();
    TestNotNull(TEXT("Test world created"), TestWorld);

    // Create game instance
    UGameInstance* GameInstance = NewObject<UGameInstance>();
    TestNotNull(TEXT("Game instance created"), GameInstance);

    // Get performance telemetry subsystem
    UGSDPerformanceTelemetry* PerfTelemetry = GameInstance->GetSubsystem<UGSDPerformanceTelemetry>();
    TestNotNull(TEXT("Performance telemetry subsystem exists"), PerfTelemetry);

    // Verify default configuration
    TestEqual(TEXT("Default hitch threshold is 16.67ms"),
        PerfTelemetry->HitchThresholdMs, 16.67f);

    TestEqual(TEXT("Default actor count interval is 5.0s"),
        PerfTelemetry->ActorCountInterval, 5.0f);

    return true;
}

// Test: Frame time recording and averaging
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDFrameTimeTest,
    "GSD.Telemetry.PerformanceTelemetry.FrameTime",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDFrameTimeTest::RunTest(const FString& Parameters)
{
    UGameInstance* GameInstance = NewObject<UGameInstance>();
    UGSDPerformanceTelemetry* PerfTelemetry = GameInstance->GetSubsystem<UGSDPerformanceTelemetry>();

    const FName DistrictName = TEXT("TestDistrict");

    // Record frame times
    PerfTelemetry->RecordFrameTime(16.0f, DistrictName);
    PerfTelemetry->RecordFrameTime(17.0f, DistrictName);
    PerfTelemetry->RecordFrameTime(16.5f, DistrictName);

    // Get average
    const float AverageFrameTime = PerfTelemetry->GetAverageFrameTimeMs(DistrictName);

    // Verify average (should be approximately 16.5ms)
    TestEqual(TEXT("Average frame time is correct"),
        AverageFrameTime, 16.5f);

    return true;
}

// Test: Hitch detection
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDHitchDetectionTest,
    "GSD.Telemetry.PerformanceTelemetry.HitchDetection",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDHitchDetectionTest::RunTest(const FString& Parameters)
{
    UGameInstance* GameInstance = NewObject<UGameInstance>();
    UGSDPerformanceTelemetry* PerfTelemetry = GameInstance->GetSubsystem<UGSDPerformanceTelemetry>();

    const FName DistrictName = TEXT("TestDistrict");

    // Record normal frame (no hitch)
    PerfTelemetry->RecordFrameTime(16.0f, DistrictName);
    TestEqual(TEXT("No hitches detected yet"),
        PerfTelemetry->GetHitchCount(DistrictName), 0);

    // Record hitch frame (exceeds 16.67ms threshold)
    PerfTelemetry->RecordFrameTime(33.0f, DistrictName);
    TestEqual(TEXT("Hitch detected"),
        PerfTelemetry->GetHitchCount(DistrictName), 1);

    // Record another hitch
    PerfTelemetry->RecordFrameTime(25.0f, DistrictName);
    TestEqual(TEXT("Second hitch detected"),
        PerfTelemetry->GetHitchCount(DistrictName), 2);

    return true;
}

// Test: Circular buffer frame time history
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDFrameTimeHistoryTest,
    "GSD.Telemetry.Types.FrameTimeHistory",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDFrameTimeHistoryTest::RunTest(const FString& Parameters)
{
    FGSDFrameTimeHistory History;

    // Add samples up to max
    for (int32 i = 0; i < 60; i++)
    {
        History.AddFrameTime(16.0f);
    }

    TestEqual(TEXT("Buffer has 60 samples"),
        History.GetSampleCount(), 60);

    TestEqual(TEXT("Average is 16.0ms"),
        History.GetAverageMs(), 16.0f);

    // Add one more sample (should wrap around)
    History.AddFrameTime(32.0f);

    TestEqual(TEXT("Buffer still has 60 samples after wrap"),
        History.GetSampleCount(), 60);

    // Average should change slightly (one 32.0ms sample replaced a 16.0ms sample)
    const float NewAverage = History.GetAverageMs();
    TestTrue(TEXT("Average changed after wrap"),
        NewAverage > 16.0f && NewAverage < 17.0f);

    return true;
}

// Test: Streaming telemetry cell load tracking
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDStreamingTelemetryTest,
    "GSD.Telemetry.StreamingTelemetry.CellLoadTimes",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDStreamingTelemetryTest::RunTest(const FString& Parameters)
{
    UGameInstance* GameInstance = NewObject<UGameInstance>();
    UGSDStreamingTelemetry* StreamingTelemetry = GameInstance->GetSubsystem<UGSDStreamingTelemetry>();

    const FName DistrictName = TEXT("District_A");
    const FName CellName1 = TEXT("Cell_1_1");
    const FName CellName2 = TEXT("Cell_1_2");

    // Record cell load times
    StreamingTelemetry->RecordCellLoadTime(CellName1, 50.0f, DistrictName);
    StreamingTelemetry->RecordCellLoadTime(CellName2, 75.0f, DistrictName);

    // Verify average
    const float AverageLoadTime = StreamingTelemetry->GetAverageCellLoadTimeMs(DistrictName);
    TestEqual(TEXT("Average cell load time is correct"),
        AverageLoadTime, 62.5f);

    // Verify total cells loaded
    TestEqual(TEXT("Total cells loaded is 2"),
        StreamingTelemetry->GetTotalCellsLoaded(), 2);

    // Verify max cell load time
    TestEqual(TEXT("Max cell load time is 75.0ms"),
        StreamingTelemetry->GetMaxCellLoadTimeMs(), 75.0f);

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro
- Test subsystem initialization
- Test frame time recording and averaging
- Test hitch detection
- Test circular buffer wraparound
- Test streaming telemetry cell load tracking
- All tests use EAutomationTestFlags::ProductFilter
</action>
  <verify>
    ```bash
    # Verify test file exists
    test -f Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp \
      && echo "Test file exists" || echo "ERROR: Test file missing"

    # Verify test implementations
    grep -q "IMPLEMENT_SIMPLE_AUTOMATION_TEST" \
      Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp \
      && echo "Automation tests defined" || echo "ERROR: No automation tests"

    # Verify specific tests
    grep -q "FGSDPerformanceTelemetryInitTest" \
      Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp \
      && echo "Init test defined" || echo "ERROR: Init test missing"

    grep -q "FGSDFrameTimeTest" \
      Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp \
      && echo "Frame time test defined" || echo "ERROR: Frame time test missing"

    grep -q "FGSDHitchDetectionTest" \
      Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp \
      && echo "Hitch detection test defined" || echo "ERROR: Hitch detection test missing"

    # Count tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" \
      Plugins/GSD_Telemetry/Source/GSD_Telemetry/Private/Tests/GSDTelemetryTests.cpp)
    echo "Total telemetry tests: $TEST_COUNT (expected 5)"
    ```
  </verify>
  <done>
Telemetry subsystem tests created with:
- GSDTelemetryTests.cpp with 5 automation tests
- FGSDPerformanceTelemetryInitTest verifying initialization
- FGSDFrameTimeTest verifying frame time recording and averaging
- FGSDHitchDetectionTest verifying hitch detection
- FGSDFrameTimeHistoryTest verifying circular buffer
- FGSDStreamingTelemetryTest verifying cell load tracking
- All tests use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro
- ProductFilter for inclusion in automation runs
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Validation Commandlet Tests</name>
  <files>Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp</files>
  <action>
Create automation tests for validation commandlets and editor widget.

**GSDValidationTests.cpp:**
```cpp
#include "CoreMinimal.h"
#include "Misc/AutomationTest.h"
#include "Types/GSDValidationTypes.h"
#include "Widgets/GSDValidationDashboardWidget.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test: Validation result helper methods
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDValidationResultTest,
    "GSD.Validation.Types.ValidationResult",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDValidationResultTest::RunTest(const FString& Parameters)
{
    FGSDValidationResult Result;

    // Verify initial state
    TestTrue(TEXT("Result initially passed"), Result.bPassed);
    TestEqual(TEXT("Initial error count is 0"), Result.ErrorCount, 0);
    TestEqual(TEXT("Initial warning count is 0"), Result.WarningCount, 0);

    // Add error
    Result.AddError(TEXT("/Game/Test/Asset"), TEXT("SizeExceeded"),
        TEXT("Asset exceeds budget"), TEXT("Reduce size"));

    TestFalse(TEXT("Result failed after error"), Result.bPassed);
    TestEqual(TEXT("Error count is 1"), Result.ErrorCount, 1);
    TestEqual(TEXT("Issues array has 1 item"), Result.Issues.Num(), 1);

    // Add warning
    Result.AddWarning(TEXT("/Game/Test/Asset2"), TEXT("HighSize"),
        TEXT("Asset approaching budget"), TEXT("Consider reducing"));

    TestFalse(TEXT("Result still failed"), Result.bPassed);
    TestEqual(TEXT("Error count still 1"), Result.ErrorCount, 1);
    TestEqual(TEXT("Warning count is 1"), Result.WarningCount, 1);
    TestEqual(TEXT("Issues array has 2 items"), Result.Issues.Num(), 2);

    return true;
}

// Test: Asset budget configuration
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDAssetBudgetTest,
    "GSD.Validation.Types.AssetBudget",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDAssetBudgetTest::RunTest(const FString& Parameters)
{
    FGSDAssetBudget Budget;

    Budget.AssetType = TEXT("StaticMesh");
    Budget.MaxSizeMB = 50.0f;
    Budget.Description = TEXT("Static mesh budget");

    TestEqual(TEXT("Asset type is StaticMesh"), Budget.AssetType, TEXT("StaticMesh"));
    TestEqual(TEXT("Max size is 50.0 MB"), Budget.MaxSizeMB, 50.0f);
    TestFalse(TEXT("Description is not empty"), Budget.Description.IsEmpty());

    return true;
}

// Test: World Partition validation config
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDWPValidationConfigTest,
    "GSD.Validation.Types.WPValidationConfig",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDWPValidationConfigTest::RunTest(const FString& Parameters)
{
    FGSDWorldPartitionValidationConfig Config;

    // Verify defaults
    TestEqual(TEXT("Default min cell size is 12800 cm"),
        Config.MinCellSize, 12800.0f);

    TestEqual(TEXT("Default min HLOD layers is 3"),
        Config.MinHLODLayers, 3);

    TestEqual(TEXT("Default max loading range is 50000 cm"),
        Config.MaxLoadingRange, 50000.0f);

    TestTrue(TEXT("Data layers required by default"),
        Config.bRequireDataLayers);

    return true;
}

// Test: Performance route waypoint
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDPerfRouteWaypointTest,
    "GSD.Validation.Types.PerfRouteWaypoint",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDPerfRouteWaypointTest::RunTest(const FString& Parameters)
{
    FGSDPerfRouteWaypoint Waypoint;

    Waypoint.Location = FVector(1000.0f, 2000.0f, 0.0f);
    Waypoint.WaypointName = TEXT("TestWaypoint");
    Waypoint.ExpectedFrameTimeMs = 16.67f;

    TestEqual(TEXT("Location is correct"),
        Waypoint.Location, FVector(1000.0f, 2000.0f, 0.0f));

    TestEqual(TEXT("Waypoint name is correct"),
        Waypoint.WaypointName, TEXT("TestWaypoint"));

    TestEqual(TEXT("Expected frame time is 16.67ms"),
        Waypoint.ExpectedFrameTimeMs, 16.67f);

    return true;
}

// Test: Validation dashboard widget initialization
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDValidationDashboardWidgetTest,
    "GSD.Validation.Widget.Dashboard",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDValidationDashboardWidgetTest::RunTest(const FString& Parameters)
{
    // Create widget
    UGSDValidationDashboardWidget* Widget = NewObject<UGSDValidationDashboardWidget>();
    TestNotNull(TEXT("Widget created"), Widget);

    // Verify initial state
    TestFalse(TEXT("Not validating initially"), Widget->IsValidationRunning());
    TestFalse(TEXT("Last validation result is empty initially"),
        Widget->GetLastValidationPassed());

    // Verify methods exist (callable from Blueprint)
    TestTrue(TEXT("RunAllValidations method exists"),
        Widget->FindFunction(TEXT("RunAllValidations")) != nullptr);

    TestTrue(TEXT("ValidateAssets method exists"),
        Widget->FindFunction(TEXT("ValidateAssets")) != nullptr);

    TestTrue(TEXT("ValidateWorldPartition method exists"),
        Widget->FindFunction(TEXT("ValidateWorldPartition")) != nullptr);

    TestTrue(TEXT("RunPerformanceRoute method exists"),
        Widget->FindFunction(TEXT("RunPerformanceRoute")) != nullptr);

    return true;
}

// Test: Validation issue structure
IMPLEMENT_SIMPLE_AUTOMATION_TEST(
    FGSDValidationIssueTest,
    "GSD.Validation.Types.ValidationIssue",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDValidationIssueTest::RunTest(const FString& Parameters)
{
    FGSDValidationIssue Issue;

    Issue.AssetPath = TEXT("/Game/Test/Asset");
    Issue.IssueType = TEXT("SizeExceeded");
    Issue.Description = TEXT("Asset exceeds 100MB budget");
    Issue.Severity = 1.0f;  // Error
    Issue.Suggestion = TEXT("Reduce texture resolution");

    TestEqual(TEXT("Asset path is correct"), Issue.AssetPath, TEXT("/Game/Test/Asset"));
    TestEqual(TEXT("Issue type is correct"), Issue.IssueType, TEXT("SizeExceeded"));
    TestEqual(TEXT("Severity is 1.0 (error)"), Issue.Severity, 1.0f);
    TestFalse(TEXT("Suggestion is not empty"), Issue.Suggestion.IsEmpty());

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Test FGSDValidationResult helper methods (AddError, AddWarning)
- Test FGSDAssetBudget configuration
- Test FGSDWorldPartitionValidationConfig defaults
- Test FGSDPerfRouteWaypoint structure
- Test UGSDValidationDashboardWidget initialization
- Test FGSDValidationIssue structure
- Verify Blueprint callable methods exist
</action>
  <verify>
    ```bash
    # Verify test file exists
    test -f Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp \
      && echo "Test file exists" || echo "ERROR: Test file missing"

    # Verify test implementations
    grep -q "IMPLEMENT_SIMPLE_AUTOMATION_TEST" \
      Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp \
      && echo "Automation tests defined" || echo "ERROR: No automation tests"

    # Verify specific tests
    grep -q "FGSDValidationResultTest" \
      Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp \
      && echo "Validation result test defined" || echo "ERROR: Validation result test missing"

    grep -q "FGSDValidationDashboardWidgetTest" \
      Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp \
      && echo "Widget test defined" || echo "ERROR: Widget test missing"

    # Count tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" \
      Plugins/GSD_ValidationTools/Source/GSD_ValidationTools/Private/Tests/GSDValidationTests.cpp)
    echo "Total validation tests: $TEST_COUNT (expected 6)"
    ```
  </verify>
  <done>
Validation commandlet tests created with:
- GSDValidationTests.cpp with 6 automation tests
- FGSDValidationResultTest verifying AddError/AddWarning helpers
- FGSDAssetBudgetTest verifying budget configuration
- FGSDWPValidationConfigTest verifying WP validation defaults
- FGSDPerfRouteWaypointTest verifying waypoint structure
- FGSDValidationDashboardWidgetTest verifying widget initialization
- FGSDValidationIssueTest verifying issue structure
- All tests use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro
- ProductFilter for inclusion in automation runs
  </done>
</task>

</tasks>

<verification>
1. All telemetry subsystems have tests
2. All validation types have tests
3. Editor widget has initialization test
4. Tests compile and run in automation framework
5. Tests verify core functionality (not exhaustive edge cases)
</verification>

<success_criteria>
- GSDTelemetryTests.cpp provides 5 tests for telemetry subsystems
- GSDValidationTests.cpp provides 6 tests for validation types and widgets
- All tests use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro
- Tests verify initialization, functionality, and data structures
- ProductFilter ensures tests run in automation suites
</success_criteria>

<output>
After completion, create `.planning/phases/10-telemetry-validation/10-10-SUMMARY.md`
</output>
