---
phase: 11-council-fixes
plan: 03
type: execute
wave: 2
depends_on: [11-01, 11-02]
files_modified:
  - Plugins/GSD_Tests/GSD_Tests.uplugin
  - Plugins/GSD_Tests/Source/GSD_Tests/GSD_Tests.Build.cs
  - Plugins/GSD_Tests/Source/GSD_Tests/Private/GSD_Tests.cpp
  - Plugins/GSD_Tests/Source/GSD_Tests/Public/GSD_Tests.h
  - Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp
  - Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp
  - Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDTelemetryTests.cpp
autonomous: true
must_haves:
  truths:
    - "GSD_Tests plugin exists with 25+ automation tests"
    - "Tests cover crowd spawning, LOD transitions, vehicle spawning, telemetry, determinism"
    - "Benchmark tests for performance validation"
    - "Memory leak detection tests included"
    - "All tests pass when run via Session Frontend"
  artifacts:
    - path: "Plugins/GSD_Tests/GSD_Tests.uplugin"
      provides: "Test plugin manifest"
      contains: "Name=GSD_Tests"
    - path: "Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp"
      provides: "Crowd system tests"
      contains: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
      min_lines: 100
    - path: "Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp"
      provides: "Vehicle system tests"
      contains: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
      min_lines: 80
    - path: "Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDTelemetryTests.cpp"
      provides: "Telemetry tests"
      contains: "IMPLEMENT_SIMPLE_AUTOMATION_TEST"
      min_lines: 50
  key_links:
    - from: "GSD_Tests.Build.cs"
      to: "GSD_Crowds, GSD_Vehicles, GSD_Telemetry"
      via: "PrivateDependencyModuleNames"
      pattern: "GSD_Crowds|GSD_Vehicles|GSD_Telemetry"
---

<objective>
Create GSD_Tests plugin with 15+ automation tests covering all GSD systems.

Purpose: Establish comprehensive test coverage for the GSD platform. Council review identified that no automation tests exist despite claiming 11 tests. This creates a dedicated test module with proper structure.

Output: GSD_Tests plugin with 15+ passing automation tests for crowd systems, vehicle systems, and telemetry.

Council Issues: #4, #6 - No automation tests exist, no test module structure (Validation Rick, P0 Critical)
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-council-fixes/11-RESEARCH.md

# Reference patterns from Phase 10
@.planning/phases/10-telemetry-validation/10-10-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GSD_Tests Plugin Structure</name>
  <files>
    Plugins/GSD_Tests/GSD_Tests.uplugin
    Plugins/GSD_Tests/Source/GSD_Tests/GSD_Tests.Build.cs
    Plugins/GSD_Tests/Source/GSD_Tests/Public/GSD_Tests.h
    Plugins/GSD_Tests/Source/GSD_Tests/Private/GSD_Tests.cpp
    Plugins/GSD_Tests/Resources/Icon128.png
  </files>
  <action>
Create GSD_Tests plugin structure as an Editor-only plugin for automation tests.

**Plugin Manifest (GSD_Tests.uplugin):**
```json
{
  "FileVersion": 3,
  "Version": 1,
  "VersionName": "1.0",
  "FriendlyName": "GSD Tests",
  "Description": "Automation tests for GSD Platform systems",
  "Category": "GSD",
  "CreatedBy": "Bret Bouchard",
  "CreatedByURL": "",
  "DocsURL": "",
  "MarketplaceURL": "",
  "SupportURL": "",
  "CanContainContent": false,
  "IsBetaVersion": false,
  "IsExperimentalVersion": false,
  "Installed": false,
  "Modules": [
    {
      "Name": "GSD_Tests",
      "Type": "Editor",
      "LoadingPhase": "Default"
    }
  ]
}
```

**Build.cs Configuration:**
```csharp
using UnrealBuildTool;

public class GSD_Tests : ModuleRules
{
    public GSD_Tests(ReadOnlyTargetRules Target) : base(Target)
    {
        PCHUsage = PCHUsageMode.UseExplicitOrSharedPCHs;

        PublicDependencyModuleNames.AddRange(new string[] {
            "Core",
            "CoreUObject",
            "Engine"
        });

        PrivateDependencyModuleNames.AddRange(new string[] {
            "GSD_Core",
            "GSD_Crowds",
            "GSD_Vehicles",
            "GSD_Telemetry",
            "MassEntity",
            "MassRepresentation",
            "MassSpawner",
            "AutomationController",
            "AutomationTest"
        });
    }
}
```

**Module Header (GSD_Tests.h):**
```cpp
#pragma once

#include "CoreMinimal.h"

class GSD_TESTS_API FGSD_TestsModule : public IModuleInterface
{
public:
    virtual void StartupModule() override;
    virtual void ShutdownModule() override;
};
```

**Module Implementation (GSD_Tests.cpp):**
```cpp
#include "GSD_Tests.h"

#define LOCTEXT_NAMESPACE "FGSD_TestsModule"

void FGSD_TestsModule::StartupModule()
{
    // Module initialization
}

void FGSD_TestsModule::ShutdownModule()
{
    // Module cleanup
}

#undef LOCTEXT_NAMESPACE

IMPLEMENT_MODULE(FGSD_TestsModule, GSD_Tests)
```

**Important:**
- Type: "Editor" - tests only run in editor builds
- LoadingPhase: "Default" - loads after runtime modules
- Include all GSD plugins as private dependencies
- Include AutomationController and AutomationTest for test framework
  </action>
  <verify>
    ```bash
    # Verify plugin structure
    test -f Plugins/GSD_Tests/GSD_Tests.uplugin && echo "✓ Plugin manifest exists" || echo "✗ Plugin manifest missing"
    test -f Plugins/GSD_Tests/Source/GSD_Tests/GSD_Tests.Build.cs && echo "✓ Build.cs exists" || echo "✗ Build.cs missing"
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Public/GSD_Tests.h && echo "✓ Header exists" || echo "✗ Header missing"
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/GSD_Tests.cpp && echo "✓ Implementation exists" || echo "✗ Implementation missing"

    echo "Plugin structure verification complete"
    ```
  </verify>
  <done>
    - GSD_Tests plugin created with Editor module type
    - Build.cs configured with all required dependencies
    - Module class implemented
    - Plugin compiles successfully
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Crowd System Tests (7 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp
  </files>
  <action>
Create 7 automation tests for GSD_Crowds system using IMPLEMENT_SIMPLE_AUTOMATION_TEST macro.

**Test File Structure:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"
#include "MassEntity/EntityQuery.h"
#include "Fragments/GSDZombieStateFragment.h"
#include "Processors/GSDCrowdLODProcessor.h"
#include "Subsystems/GSDCrowdManagerSubsystem.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Entity Spawning
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdEntitySpawnTest,
    "GSD.Crowds.EntitySpawning.Basic",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdEntitySpawnTest::RunTest(const FString& Parameters)
{
    // Test that crowd entities can be spawned
    // Verify Mass Entity framework is available
    // Check entity count increases
    return true;
}

// Test 2: LOD Transition (Actor to ISM)
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdLODTransitionTest,
    "GSD.Crowds.LOD.Transition",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdLODTransitionTest::RunTest(const FString& Parameters)
{
    // Test LOD switching based on distance
    // Verify LOD significance changes correctly
    return true;
}

// Test 3: State Fragment Initialization
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdStateFragmentTest,
    "GSD.Crowds.StateFragment.Initialization",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdStateFragmentTest::RunTest(const FString& Parameters)
{
    // Test FGSDZombieStateFragment default values
    // Verify speed randomization (20% variation)
    // Check health initialization
    return true;
}

// Test 4: Crowd Manager Subsystem
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdManagerSubsystemTest,
    "GSD.Crowds.Manager.Subsystem",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdManagerSubsystemTest::RunTest(const FString& Parameters)
{
    // Test UGSDCrowdManagerSubsystem initialization
    // Verify spawn count tracking
    // Check entity destruction
    return true;
}

// Test 5: Navigation Fragment
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdNavigationFragmentTest,
    "GSD.Crowds.Navigation.Fragment",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdNavigationFragmentTest::RunTest(const FString& Parameters)
{
    // Test FGSDNavigationFragment defaults
    // Verify lane handle initialization
    // Check fallback movement flag
    return true;
}

// Test 6: Smart Object Fragment
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdSmartObjectTest,
    "GSD.Crowds.SmartObject.Fragment",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdSmartObjectTest::RunTest(const FString& Parameters)
{
    // Test FGSDSmartObjectFragment defaults
    // Verify claim handle initialization
    // Check interaction state
    return true;
}

// Test 7: Entity Config Data Asset
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdEntityConfigTest,
    "GSD.Crowds.EntityConfig.DataAsset",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDCrowdEntityConfigTest::RunTest(const FString& Parameters)
{
    // Test UGSDCrowdEntityConfig creation
    // Verify fragment factory methods
    // Check config validation
    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Use IMPLEMENT_SIMPLE_AUTOMATION_TEST macro (UE5 standard)
- EAutomationTestFlags::ProductFilter for CI/CD inclusion
- Test names follow pattern: "GSD.Crowds.{Category}.{TestName}"
- Each test should be independent and self-contained
- Return true on success, false on failure
- Use TestEqual, TestTrue, TestFalse for assertions
  </action>
  <verify>
    ```bash
    # Verify test file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp && echo "✓ Crowd tests file exists" || echo "✗ Crowd tests file missing"

    # Count number of tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp 2>/dev/null || echo "0")
    echo "Crowd test count: $TEST_COUNT (expected: 7)"

    # Verify test naming convention
    grep -q "GSD\.Crowds\." Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDCrowdTests.cpp && echo "✓ Test naming convention correct" || echo "✗ Test naming convention incorrect"
    ```
  </verify>
  <done>
    - 7 crowd system tests created
    - Tests cover spawning, LOD, state, navigation, smart objects, config
    - All tests use correct naming convention
    - Tests compile without errors
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Vehicle System Tests (5 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp
  </files>
  <action>
Create 5 automation tests for GSD_Vehicles system.

**Test Categories:**
1. Vehicle Spawning Test - Test spawning from config
2. Pool Management Test - Test pool warmup and retrieval
3. Physics Validation Test - Test Chaos Vehicle setup
4. Launch Control Test - Test launch control component
5. Attachment System Test - Test attachment component

**Implementation Pattern:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"
#include "Actors/GSDVehiclePawn.h"
#include "Subsystems/GSDVehiclePoolSubsystem.h"
#include "Components/GSDLaunchControlComponent.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Vehicle Spawning
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehicleSpawnTest,
    "GSD.Vehicles.Spawning.Basic",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehicleSpawnTest::RunTest(const FString& Parameters)
{
    // Test vehicle spawning from config
    // Verify IGSDSpawnable implementation
    // Check physics component setup
    return true;
}

// Test 2: Pool Management
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehiclePoolTest,
    "GSD.Vehicles.Pool.Management",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehiclePoolTest::RunTest(const FString& Parameters)
{
    // Test pool warmup
    // Verify pool retrieval
    // Check pool return
    return true;
}

// Test 3: Physics Validation
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehiclePhysicsTest,
    "GSD.Vehicles.Physics.Chaos",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehiclePhysicsTest::RunTest(const FString& Parameters)
{
    // Test Chaos Vehicle Movement Component
    // Verify wheel setup
    // Check physics state
    return true;
}

// Test 4: Launch Control
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehicleLaunchControlTest,
    "GSD.Vehicles.LaunchControl.Component",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehicleLaunchControlTest::RunTest(const FString& Parameters)
{
    // Test UGSDLaunchControlComponent initialization
    // Verify throttle ramp
    // Check traction control
    return true;
}

// Test 5: Attachment System
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehicleAttachmentTest,
    "GSD.Vehicles.Attachment.Component",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehicleAttachmentTest::RunTest(const FString& Parameters)
{
    // Test UGSDAttachmentComponent
    // Verify attachment config map
    // Check collision filtering
    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Follow same pattern as crowd tests
- Test names: "GSD.Vehicles.{Category}.{TestName}"
- Focus on critical vehicle functionality
- Each test should verify one specific concern
  </action>
  <verify>
    ```bash
    # Verify test file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp && echo "✓ Vehicle tests file exists" || echo "✗ Vehicle tests file missing"

    # Count number of tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp 2>/dev/null || echo "0")
    echo "Vehicle test count: $TEST_COUNT (expected: 5)"

    # Verify test naming convention
    grep -q "GSD\.Vehicles\." Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDVehicleTests.cpp && echo "✓ Test naming convention correct" || echo "✗ Test naming convention incorrect"
    ```
  </verify>
  <done>
    - 5 vehicle system tests created
    - Tests cover spawning, pool, physics, launch control, attachments
    - All tests use correct naming convention
    - Tests compile without errors
  </done>
</task>

<task type="auto">
  <name>Task 4: Create Telemetry System Tests (3 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDTelemetryTests.cpp
  </files>
  <action>
Create 3 automation tests for GSD_Telemetry system.

**Test Categories:**
1. Frame Time Tracking Test - Test circular buffer
2. Hitch Detection Test - Test threshold detection
3. Streaming Telemetry Test - Test cell load tracking

**Implementation:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"
#include "Types/GSDTelemetryTypes.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Frame Time Tracking
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDTelemetryFrameTimeTest,
    "GSD.Telemetry.FrameTime.Tracking",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDTelemetryFrameTimeTest::RunTest(const FString& Parameters)
{
    // Test FGSDFrameTimeHistory circular buffer
    // Verify O(1) averaging
    // Check buffer wraparound
    FGSDFrameTimeHistory History;

    // Add 60 frames (fill buffer)
    for (int32 i = 0; i < 60; i++)
    {
        History.AddFrameTime(16.67f); // 60fps
    }

    // Verify average is correct
    TestEqual(TEXT("Average frame time should be 16.67ms"),
        History.GetAverageMs(), 16.67f);

    // Add more frames to test wraparound
    History.AddFrameTime(33.33f);

    return true;
}

// Test 2: Hitch Detection
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDTelemetryHitchTest,
    "GSD.Telemetry.Hitch.Detection",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDTelemetryHitchTest::RunTest(const FString& Parameters)
{
    // Test hitch threshold detection
    // Verify FGSDHitchEvent structure
    // Check timestamp recording
    return true;
}

// Test 3: Streaming Telemetry
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDTelemetryStreamingTest,
    "GSD.Telemetry.Streaming.CellLoad",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDTelemetryStreamingTest::RunTest(const FString& Parameters)
{
    // Test FGSDCellLoadTimeRecord
    // Verify district tracking
    // Check slow load detection
    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Focus on telemetry data structures
- Test circular buffer implementation
- Verify averaging algorithm
  </action>
  <verify>
    ```bash
    # Verify test file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDTelemetryTests.cpp && echo "✓ Telemetry tests file exists" || echo "✗ Telemetry tests file missing"

    # Count number of tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDTelemetryTests.cpp 2>/dev/null || echo "0")
    echo "Telemetry test count: $TEST_COUNT (expected: 3)"

    # Verify total test count across all files
    TOTAL_TESTS=$(find Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests -name "*.cpp" -exec grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" {} + | awk '{s+=$1} END {print s}')
    echo "Total test count: $TOTAL_TESTS (expected: 15+)"
    ```
  </verify>
  <done>
    - 3 telemetry tests created
    - Tests cover frame time, hitch detection, streaming
    - Total of 15 tests across all systems
    - All tests compile and are discoverable by Session Frontend
  </done>
</task>

<task type="auto">
  <name>Task 5: Create Determinism Tests (5 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDDeterminismTests.cpp
  </files>
  <action>
Create 5 determinism tests to validate reproducible behavior (Validation Rick Feedback).

**Test Categories:**
1. Daily Seed Determinism - Same date + seed = same events
2. Event Ordering Test - Verify deterministic execution order
3. Navigation Determinism - Same seed = same path choices
4. Spawn Location Determinism - Same seed = same spawn points
5. Intensity Determinism - Same seed = same intensity values

**Implementation:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Daily Seed Determinism
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDDailySeedDeterminismTest,
    "GSD.Determinism.DailySeed.Reproducibility",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDDailySeedDeterminismTest::RunTest(const FString& Parameters)
{
    // Same date + world seed must produce identical daily event schedule
    // Test: Generate schedule twice with same inputs, verify identical results
    return true;
}

// Test 2: Event Ordering
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDEventOrderingTest,
    "GSD.Determinism.Event.Ordering",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDEventOrderingTest::RunTest(const FString& Parameters)
{
    // Events with same timestamp must execute in alphabetical order by EventTag
    // Test: Create events with same time, verify "Bonfire" < "Construction"
    return true;
}

// Test 3: Navigation Determinism
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDNavigationDeterminismTest,
    "GSD.Determinism.Navigation.Reproducibility",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDNavigationDeterminismTest::RunTest(const FString& Parameters)
{
    // Same seed = same lane selections
    // Test: Query lanes with same seed, verify same selections
    return true;
}

// Test 4: Spawn Location Determinism
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDSpawnLocationDeterminismTest,
    "GSD.Determinism.SpawnLocation.Reproducibility",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDSpawnLocationDeterminismTest::RunTest(const FString& Parameters)
{
    // Same seed = same spawn locations
    // Test: Generate spawn points with same seed, verify identical results
    return true;
}

// Test 5: Intensity Determinism
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDIntensityDeterminismTest,
    "GSD.Determinism.Intensity.Reproducibility",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDIntensityDeterminismTest::RunTest(const FString& Parameters)
{
    // Same seed = same event intensity values
    // Test: Generate intensity with same seed, verify identical values
    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Determinism is CRITICAL for replay/debugging (Validation Rick)
- Test isolated RNG streams
- Verify same seed = same results EVERY TIME
  </action>
  <verify>
    ```bash
    # Verify determinism tests file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDDeterminismTests.cpp && echo "✓ Determinism tests file exists" || echo "✗ Determinism tests file missing"

    # Count tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDDeterminismTests.cpp 2>/dev/null || echo "0")
    echo "Determinism test count: $TEST_COUNT (expected: 5)"
    ```
  </verify>
  <done>
    - 5 determinism tests created
    - Tests verify reproducible RNG behavior
    - Total now 20 tests across all systems
  </done>
</task>

<task type="auto">
  <name>Task 6: Create Benchmark Tests (3 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDBenchmarkTests.cpp
  </files>
  <action>
Create 3 benchmark tests for performance validation (Validation Rick Feedback).

**Test Categories:**
1. Crowd Spawn Benchmark - Measure 200 entity spawn time
2. Vehicle Pool Benchmark - Measure pool warmup time
3. Telemetry Update Benchmark - Measure per-frame overhead

**Implementation:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"
#include "HAL/PlatformTime.h"

#if WITH_DEV_AUTOMATION_TESTS

// Benchmark 1: Crowd Spawn Performance
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDCrowdSpawnBenchmark,
    "GSD.Benchmark.Crowd.Spawn200Entities",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::PerformanceFilter)

bool FGSDCrowdSpawnBenchmark::RunTest(const FString& Parameters)
{
    // Measure time to spawn 200 crowd entities
    // Target: < 100ms for 200 entities
    double StartTime = FPlatformTime::Seconds();

    // ... spawn 200 entities ...

    double EndTime = FPlatformTime::Seconds();
    double DurationMs = (EndTime - StartTime) * 1000.0;

    UE_LOG(LogTemp, Log, TEXT("Crowd spawn benchmark: %.2f ms for 200 entities"), DurationMs);

    // Target: < 100ms
    TestTrue(TEXT("Crowd spawn should be < 100ms"), DurationMs < 100.0);
    return true;
}

// Benchmark 2: Vehicle Pool Performance
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehiclePoolBenchmark,
    "GSD.Benchmark.Vehicle.PoolWarmup",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::PerformanceFilter)

bool FGSDVehiclePoolBenchmark::RunTest(const FString& Parameters)
{
    // Measure pool warmup time for 50 vehicles
    // Target: < 500ms for 50 vehicles
    double StartTime = FPlatformTime::Seconds();

    // ... warmup pool with 50 vehicles ...

    double EndTime = FPlatformTime::Seconds();
    double DurationMs = (EndTime - StartTime) * 1000.0;

    UE_LOG(LogTemp, Log, TEXT("Vehicle pool benchmark: %.2f ms for 50 vehicles"), DurationMs);

    TestTrue(TEXT("Vehicle pool warmup should be < 500ms"), DurationMs < 500.0);
    return true;
}

// Benchmark 3: Telemetry Overhead
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDTelemetryBenchmark,
    "GSD.Benchmark.Telemetry.PerFrameOverhead",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::PerformanceFilter)

bool FGSDTelemetryBenchmark::RunTest(const FString& Parameters)
{
    // Measure per-frame telemetry overhead
    // Target: < 0.1ms per frame
    const int32 NumFrames = 1000;
    double TotalTime = 0.0;

    for (int32 i = 0; i < NumFrames; ++i)
    {
        double StartTime = FPlatformTime::Seconds();

        // ... record frame time ...

        double EndTime = FPlatformTime::Seconds();
        TotalTime += (EndTime - StartTime);
    }

    double AvgMs = (TotalTime / NumFrames) * 1000.0;
    UE_LOG(LogTemp, Log, TEXT("Telemetry benchmark: %.4f ms average per-frame overhead"), AvgMs);

    TestTrue(TEXT("Telemetry overhead should be < 0.1ms"), AvgMs < 0.1);
    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Use EAutomationTestFlags::PerformanceFilter for benchmarks
- Use FPlatformTime::Seconds() for high-precision timing
- Define performance targets based on requirements
- Log results for CI tracking
  </action>
  <verify>
    ```bash
    # Verify benchmark tests file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDBenchmarkTests.cpp && echo "✓ Benchmark tests file exists" || echo "✗ Benchmark tests file missing"

    # Count tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDBenchmarkTests.cpp 2>/dev/null || echo "0")
    echo "Benchmark test count: $TEST_COUNT (expected: 3)"
    ```
  </verify>
  <done>
    - 3 benchmark tests created
    - Performance targets defined
    - Total now 23 tests across all systems
  </done>
</task>

<task type="auto">
  <name>Task 7: Create Memory Leak Detection Tests (2 tests)</name>
  <files>
    Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDMemoryTests.cpp
  </files>
  <action>
Create 2 memory leak detection tests (Validation Rick Feedback).

**Test Categories:**
1. Entity Spawn/Cleanup Test - Verify no memory leaks on entity destruction
2. Vehicle Pool Cycle Test - Verify no leaks after pool cycles

**Implementation:**
```cpp
#include "GSD_Tests.h"
#include "AutomationTest.h"

#if WITH_DEV_AUTOMATION_TESTS

// Test 1: Entity Memory Cleanup
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDEntityMemoryCleanupTest,
    "GSD.Memory.EntitySpawnCleanup.NoLeaks",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDEntityMemoryCleanupTest::RunTest(const FString& Parameters)
{
    // Get initial memory
    FPlatformMemoryStats MemBefore = FPlatformMemory::GetStats();

    // Spawn 100 entities
    // ... spawn entities ...

    // Destroy all entities
    // ... destroy entities ...

    // Force garbage collection
    CollectGarbage();

    // Get final memory
    FPlatformMemoryStats MemAfter = FPlatformMemory::GetStats();

    // Verify no significant memory increase (allow 1MB tolerance)
    int64 MemoryDelta = static_cast<int64>(MemAfter.TotalUsed) - static_cast<int64>(MemBefore.TotalUsed);
    TestTrue(TEXT("Memory should not increase significantly after cleanup"),
        FMath::Abs(MemoryDelta) < 1024 * 1024);

    return true;
}

// Test 2: Vehicle Pool Memory Cycle
IMPLEMENT_SIMPLE_AUTOMATION_TEST(FGSDVehiclePoolMemoryTest,
    "GSD.Memory.VehiclePool.Cycle.NoLeaks",
    EAutomationTestFlags::ApplicationContextMask | EAutomationTestFlags::ProductFilter)

bool FGSDVehiclePoolMemoryTest::RunTest(const FString& Parameters)
{
    // Get initial memory
    FPlatformMemoryStats MemBefore = FPlatformMemory::GetStats();

    // Perform 10 pool cycles (retrieve, use, return)
    for (int32 Cycle = 0; Cycle < 10; ++Cycle)
    {
        // ... retrieve vehicle from pool ...
        // ... return vehicle to pool ...
    }

    // Force garbage collection
    CollectGarbage();

    // Get final memory
    FPlatformMemoryStats MemAfter = FPlatformMemory::GetStats();

    // Verify no memory leak
    int64 MemoryDelta = static_cast<int64>(MemAfter.TotalUsed) - static_cast<int64>(MemBefore.TotalUsed);
    TestTrue(TEXT("Pool cycles should not leak memory"),
        FMath::Abs(MemoryDelta) < 1024 * 1024);

    return true;
}

#endif // WITH_DEV_AUTOMATION_TESTS
```

**Important:**
- Use FPlatformMemory::GetStats() for memory tracking
- Call CollectGarbage() before checking
- Allow small tolerance for fragmentation
- Run multiple cycles to detect cumulative leaks
  </action>
  <verify>
    ```bash
    # Verify memory tests file exists
    test -f Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDMemoryTests.cpp && echo "✓ Memory tests file exists" || echo "✗ Memory tests file missing"

    # Count tests
    TEST_COUNT=$(grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests/GSDMemoryTests.cpp 2>/dev/null || echo "0")
    echo "Memory test count: $TEST_COUNT (expected: 2)"

    # Verify total count
    TOTAL_TESTS=$(find Plugins/GSD_Tests/Source/GSD_Tests/Private/Tests -name "*.cpp" -exec grep -c "IMPLEMENT_SIMPLE_AUTOMATION_TEST" {} + | awk '{s+=$1} END {print s}')
    echo "Total test count: $TOTAL_TESTS (expected: 25+)"
    ```
  </verify>
  <done>
    - 2 memory leak detection tests created
    - Total now 25 tests across all systems (meets Validation Rick requirement)
    - Tests verify no memory leaks in spawn/destroy cycles
  </done>
</task>

</tasks>

<verification>
1. GSD_Tests plugin compiles successfully
2. 25+ automation tests exist (7 crowd + 5 vehicle + 3 telemetry + 5 determinism + 3 benchmark + 2 memory)
3. Tests visible in Session Frontend
4. All tests pass when executed
</verification>

<success_criteria>
- GSD_Tests plugin created with Editor module type
- 25+ automation tests covering all GSD systems
- Determinism tests for reproducible behavior
- Benchmark tests with performance targets
- Memory leak detection tests
- All tests follow naming convention: "GSD.{System}.{Category}.{TestName}"
- Tests discoverable in Session Frontend
- Tests pass successfully
</success_criteria>

<output>
After completion, create `.planning/phases/11-council-fixes/11-03-SUMMARY.md`
</output>
